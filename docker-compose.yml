services:
  # ============================================================
  # PostgreSQL Master (Primary)
  # ============================================================
  postgres-master:
    image: postgres:16-alpine
    container_name: petpro-postgres-master
    environment:
      POSTGRES_DB: ${DB_NAME:-petpro}
      POSTGRES_USER: ${DB_USERNAME:-petpro}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8"
    volumes:
      - postgres-master-data:/var/lib/postgresql/data
      - ./docker/postgres/init-master.sh:/docker-entrypoint-initdb.d/init-master.sh
      - ./docker/postgres/pg_hba.conf:/etc/postgresql/pg_hba.conf
    ports:
      - "127.0.0.1:5432:5432"
    command: >
      postgres
      -c wal_level=replica
      -c max_wal_senders=3
      -c max_replication_slots=3
      -c hot_standby=on
      -c hba_file=/etc/postgresql/pg_hba.conf
    networks:
      - petpro-network
    healthcheck:
      test: pg_isready -U petpro -d petpro
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================================
  # PostgreSQL Slave 1 (Replica)
  # ============================================================
  postgres-slave1:
    image: postgres:16-alpine
    container_name: petpro-postgres-slave1
    environment:
      POSTGRES_DB: ${DB_NAME:-petpro}
      POSTGRES_USER: ${DB_USERNAME:-petpro}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      PGUSER: replicator
      PGPASSWORD: ${REPLICATOR_PASSWORD}
    volumes:
      - postgres-slave1-data:/var/lib/postgresql/data
      - ./docker/postgres/init-slave.sh:/init-slave.sh
    ports:
      - "127.0.0.1:5433:5432"
    depends_on:
      postgres-master:
        condition: service_healthy
    entrypoint: ["/bin/bash", "-c"]
    command:
      - |
        rm -rf /var/lib/postgresql/data/*
        until pg_basebackup -h postgres-master -D /var/lib/postgresql/data -U replicator -Fp -Xs -P -R; do
          echo 'Waiting for master to be ready...'
          sleep 5
        done
        chown -R postgres:postgres /var/lib/postgresql/data
        chmod 700 /var/lib/postgresql/data
        exec su-exec postgres postgres
    networks:
      - petpro-network
    healthcheck:
      test: pg_isready -U petpro
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================================
  # PostgreSQL Slave 2 (Replica)
  # ============================================================
  postgres-slave2:
    image: postgres:16-alpine
    container_name: petpro-postgres-slave2
    environment:
      POSTGRES_DB: ${DB_NAME:-petpro}
      POSTGRES_USER: ${DB_USERNAME:-petpro}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      PGUSER: replicator
      PGPASSWORD: ${REPLICATOR_PASSWORD}
    volumes:
      - postgres-slave2-data:/var/lib/postgresql/data
      - ./docker/postgres/init-slave.sh:/init-slave.sh
    ports:
      - "127.0.0.1:5434:5432"
    depends_on:
      postgres-master:
        condition: service_healthy
    entrypoint: ["/bin/bash", "-c"]
    command:
      - |
        rm -rf /var/lib/postgresql/data/*
        until pg_basebackup -h postgres-master -D /var/lib/postgresql/data -U replicator -Fp -Xs -P -R; do
          echo 'Waiting for master to be ready...'
          sleep 5
        done
        chown -R postgres:postgres /var/lib/postgresql/data
        chmod 700 /var/lib/postgresql/data
        exec su-exec postgres postgres
    networks:
      - petpro-network
    healthcheck:
      test: pg_isready -U petpro
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================================
  # PostgreSQL Coupon DB (별도)
  # ============================================================
  postgres-coupon:
    image: postgres:16-alpine
    container_name: petpro-postgres-coupon
    environment:
      POSTGRES_DB: petpro_coupon
      POSTGRES_USER: coupon
      POSTGRES_PASSWORD: ${COUPON_DB_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8"
    volumes:
      - postgres-coupon-data:/var/lib/postgresql/data
    ports:
      - "127.0.0.1:5435:5432"
    networks:
      - petpro-network
    healthcheck:
      test: pg_isready -U coupon -d petpro_coupon
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================================
  # MySQL Log Master (로그 DB)
  # ============================================================
  mysql-log-master:
    image: mysql:8.0.36-debian
    container_name: petpro-mysql-log-master
    environment:
      MYSQL_ROOT_PASSWORD: ${LOG_DB_ROOT_PASSWORD}
      MYSQL_DATABASE: petpro_log
      MYSQL_USER: ${LOG_DB_USERNAME:-loguser}
      MYSQL_PASSWORD: ${LOG_DB_PASSWORD}
      MYSQL_REPL_PASSWORD: ${MYSQL_REPL_PASSWORD}
    volumes:
      - mysql-log-master-data:/var/lib/mysql
      - ./docker/mysql-log/master/my.cnf:/etc/mysql/conf.d/my.cnf:ro
      - ./docker/mysql-log/master/init-master.sh:/docker-entrypoint-initdb.d/init-master.sh:ro
    ports:
      - "127.0.0.1:${LOG_DB_MASTER_PORT:-3306}:3306"
    command: >
      --server-id=1
      --log-bin=mysql-bin
      --binlog-format=ROW
      --gtid-mode=ON
      --enforce-gtid-consistency=ON
      --default-authentication-plugin=mysql_native_password
      --character-set-server=utf8mb4
      --collation-server=utf8mb4_unicode_ci
    networks:
      - petpro-network
    healthcheck:
      test: mysqladmin ping -h localhost -u root -p$${MYSQL_ROOT_PASSWORD}
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================================
  # MySQL Log Slave (로그 DB 읽기 전용)
  # ============================================================
  mysql-log-slave:
    image: mysql:8.0.36-debian
    container_name: petpro-mysql-log-slave
    environment:
      MYSQL_ROOT_PASSWORD: ${LOG_DB_ROOT_PASSWORD}
      MYSQL_DATABASE: petpro_log
      MYSQL_REPL_PASSWORD: ${MYSQL_REPL_PASSWORD}
    volumes:
      - mysql-log-slave-data:/var/lib/mysql
      - ./docker/mysql-log/slave/my.cnf:/etc/mysql/conf.d/my.cnf:ro
      - ./docker/mysql-log/slave/init-slave.sh:/docker-entrypoint-initdb.d/init-slave.sh:ro
    ports:
      - "127.0.0.1:${LOG_DB_SLAVE_PORT:-3307}:3306"
    command: >
      --server-id=2
      --gtid-mode=ON
      --enforce-gtid-consistency=ON
      --default-authentication-plugin=mysql_native_password
      --character-set-server=utf8mb4
      --collation-server=utf8mb4_unicode_ci
    depends_on:
      mysql-log-master:
        condition: service_healthy
    networks:
      - petpro-network
    healthcheck:
      test: mysqladmin ping -h localhost -u root -p$${MYSQL_ROOT_PASSWORD}
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================================
  # Redis (Cache & Session)
  # ============================================================
  redis:
    image: redis:7-alpine
    container_name: petpro-redis
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis-data:/data
    ports:
      - "127.0.0.1:6379:6379"
    networks:
      - petpro-network
    healthcheck:
      test: redis-cli -a $${REDIS_PASSWORD} ping
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================================
  # MinIO (S3 Compatible Storage)
  # ============================================================
  minio:
    image: minio/minio:RELEASE.2022-10-24T18-35-07Z
    container_name: petpro-minio
    environment:
      MINIO_ROOT_USER: ${MINIO_ACCESS_KEY:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_SECRET_KEY}
    volumes:
      - minio-data:/data
    ports:
      - "127.0.0.1:9000:9000"
      - "127.0.0.1:9001:9001"
    command: server /data --console-address ":9001"
    networks:
      - petpro-network
    healthcheck:
      test: curl -f http://localhost:9000/minio/health/live || exit 1
      interval: 30s
      timeout: 20s
      retries: 3

  # ============================================================
  # MinIO Client (Bucket 초기화)
  # ============================================================
  minio-init:
    image: minio/mc:RELEASE.2022-10-29T10-09-23Z
    container_name: petpro-minio-init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: /bin/sh -c
    command: >
      "mc alias set myminio http://minio:9000 $${MINIO_ACCESS_KEY} $${MINIO_SECRET_KEY} &&
       mc mb myminio/petpro --ignore-existing &&
       mc anonymous set download myminio/petpro/pets &&
       mc anonymous set download myminio/petpro/public &&
       echo 'MinIO bucket initialized'"
    networks:
      - petpro-network

  # ============================================================
  # Nginx (Reverse Proxy)
  # ============================================================
  nginx:
    image: nginx:alpine
    container_name: petpro-nginx
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./docker/nginx/conf.d:/etc/nginx/conf.d:ro
      - ./docker/certbot/conf:/etc/letsencrypt:ro
      - ./docker/certbot/www:/var/www/certbot:ro
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - redis
    networks:
      - petpro-network

  # ============================================================
  # Prometheus (Metrics)
  # ============================================================
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: petpro-prometheus
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "127.0.0.1:9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
      - '--web.enable-remote-write-receiver'
    networks:
      - petpro-network
    healthcheck:
      test: wget -q --spider http://localhost:9090/-/healthy || exit 1
      interval: 30s
      timeout: 10s
      retries: 3

  # ============================================================
  # Loki (Log Aggregation)
  # ============================================================
  loki:
    image: grafana/loki:2.9.2
    container_name: petpro-loki
    volumes:
      - ./docker/loki/loki-config.yml:/etc/loki/local-config.yaml:ro
      - loki-data:/loki
    ports:
      - "127.0.0.1:3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - petpro-network
    healthcheck:
      test: wget -q --spider http://localhost:3100/ready || exit 1
      interval: 30s
      timeout: 10s
      retries: 3

  # ============================================================
  # Promtail (Log Collector)
  # ============================================================
  promtail:
    image: grafana/promtail:2.9.2
    container_name: petpro-promtail
    volumes:
      - ./docker/promtail/promtail-config.yml:/etc/promtail/config.yml:ro
      - ./logs:/var/log/petpro:ro
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    networks:
      - petpro-network

  # ============================================================
  # Tempo (Distributed Tracing)
  # ============================================================
  tempo:
    image: grafana/tempo:2.3.1
    container_name: petpro-tempo
    volumes:
      - ./docker/tempo/tempo-config.yml:/etc/tempo/tempo.yaml:ro
      - tempo-data:/tmp/tempo
    ports:
      - "127.0.0.1:3200:3200"   # HTTP
      - "127.0.0.1:4317:4317"   # OTLP gRPC
      - "127.0.0.1:4318:4318"   # OTLP HTTP
      - "127.0.0.1:9411:9411"   # Zipkin
    command: -config.file=/etc/tempo/tempo.yaml
    depends_on:
      - prometheus
    networks:
      - petpro-network
    healthcheck:
      test: wget -q --spider http://localhost:3200/ready || exit 1
      interval: 30s
      timeout: 10s
      retries: 3

  # ============================================================
  # Grafana (Visualization)
  # ============================================================
  grafana:
    image: grafana/grafana:10.2.2
    container_name: petpro-grafana
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_SERVER_ROOT_URL: http://localhost:3001
    volumes:
      - grafana-data:/var/lib/grafana
      - ./docker/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./docker/grafana/dashboards:/var/lib/grafana/dashboards:ro
    ports:
      - "127.0.0.1:3001:3000"
    depends_on:
      - prometheus
      - loki
      - tempo
    networks:
      - petpro-network
    healthcheck:
      test: wget -q --spider http://localhost:3000/api/health || exit 1
      interval: 30s
      timeout: 10s
      retries: 3

# ============================================================
# Networks
# ============================================================
networks:
  petpro-network:
    driver: bridge

# ============================================================
# Volumes
# ============================================================
volumes:
  postgres-master-data:
  postgres-slave1-data:
  postgres-slave2-data:
  postgres-coupon-data:
  mysql-log-master-data:
  mysql-log-slave-data:
  redis-data:
  minio-data:
  prometheus-data:
  loki-data:
  tempo-data:
  grafana-data:
